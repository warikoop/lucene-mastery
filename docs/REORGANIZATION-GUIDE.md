# ğŸ¯ **Comprehensive Learning Environment Reorganization**

> **Objective**: Transform scattered materials into organized, production-ready learning environment
> **Key Benefits**: Independent script execution, consistent HA endpoints, single unified setup
> **Target**: Systematic progression from foundations to Senior Staff Engineer expertise

---

## ğŸ“ **New Folder Structure**

### **ğŸ—ï¸ Root Directory Organization**

```
elastic-search/
â”œâ”€â”€ 00-LEARNING-PATH-README.md                 # Master learning guide
â”œâ”€â”€ REORGANIZATION-GUIDE.md                    # This file
â”œâ”€â”€ docker-compose.yml                         # Unified HA setup (ES+Solr+OpenSearch)
â”œâ”€â”€ .env                                       # Environment configuration
â”‚
â”œâ”€â”€ ğŸ“š learning-materials/                     # All sequential learning docs
â”‚   â”œâ”€â”€ 01-lucene-architecture-deep-dive.md
â”‚   â”œâ”€â”€ 01a-lucene-component-readwrite-analysis.md
â”‚   â”œâ”€â”€ 02-fst-vs-trie-comparison.md
â”‚   â”œâ”€â”€ 03-fst-construction-algorithm.md
â”‚   â”œâ”€â”€ 04-advanced-features-hands-on-practice.md
â”‚   â”œâ”€â”€ 05-admin-interface-comparison.md
â”‚   â”œâ”€â”€ 06-advanced-features-cross-analysis.md
â”‚   â”œâ”€â”€ 07-query-language-comparison.md
â”‚   â”œâ”€â”€ 08-scoring-relevance-comparison.md
â”‚   â”œâ”€â”€ 09-aggregations-vs-faceting-comparison.md
â”‚   â”œâ”€â”€ 10-step2-function-scoring-implementation.md
â”‚   â”œâ”€â”€ 11-solr-function-scoring-fixes.md
â”‚   â”œâ”€â”€ 12-advanced-script-scoring-guide.md
â”‚   â”œâ”€â”€ 13-ml-learning-to-rank-guide.md
â”‚   â”œâ”€â”€ 14-performance-progressive-labs.md
â”‚   â”œâ”€â”€ 15-performance-benchmarking-guide.md
â”‚   â”œâ”€â”€ 16-scaling-patterns.md
â”‚   â”œâ”€â”€ 17-memory-management.md
â”‚   â”œâ”€â”€ 18-monitoring-solutions.md
â”‚   â”œâ”€â”€ 19-production-war-stories.md
â”‚   â”œâ”€â”€ 20-performance-and-production-reality.md
â”‚   â”œâ”€â”€ 21-ab-testing-framework-guide.md
â”‚   â””â”€â”€ 22-technology-selection-decision-tree.md
â”‚

â”‚
â”œâ”€â”€ ğŸ“Š labs/                                   # All hands-on laboratories
â”‚   â”œâ”€â”€ phase1-foundations/
â”‚   â”‚   â”œâ”€â”€ lab-01-lucene-internals/
â”‚   â”‚   â”œâ”€â”€ lab-02-fst-analysis/
â”‚   â”‚   â””â”€â”€ lab-03-architecture-exploration/
â”‚   â”œâ”€â”€ phase2-environment/
â”‚   â”‚   â”œâ”€â”€ lab-04-multi-platform-setup/
â”‚   â”‚   â””â”€â”€ lab-05-admin-interfaces/
â”‚   â”œâ”€â”€ phase3-core-concepts/
â”‚   â”‚   â”œâ”€â”€ lab-06-schema-management/
â”‚   â”‚   â””â”€â”€ lab-07-query-languages/
â”‚   â”œâ”€â”€ phase4-search-fundamentals/
â”‚   â”‚   â”œâ”€â”€ lab-08-basic-scoring/
â”‚   â”‚   â”œâ”€â”€ lab-09-aggregations-faceting/
â”‚   â”‚   â””â”€â”€ lab-10-function-scoring/
â”‚   â”œâ”€â”€ phase5-advanced-scoring/
â”‚   â”‚   â”œâ”€â”€ lab-11-solr-scoring-fixes/
â”‚   â”‚   â”œâ”€â”€ lab-12-script-scoring/
â”‚   â”‚   â””â”€â”€ lab-13-ml-learning-to-rank/
â”‚   â”œâ”€â”€ phase6-performance/
â”‚   â”‚   â”œâ”€â”€ lab-14-progressive-performance/
â”‚   â”‚   â”œâ”€â”€ lab-15-benchmarking/
â”‚   â”‚   â”œâ”€â”€ lab-16-scaling-patterns/
â”‚   â”‚   â”œâ”€â”€ lab-17-memory-management/
â”‚   â”‚   â””â”€â”€ lab-18-monitoring/
â”‚   â”œâ”€â”€ phase7-production/
â”‚   â”‚   â”œâ”€â”€ lab-19-war-stories/
â”‚   â”‚   â””â”€â”€ lab-20-production-reality/
â”‚   â””â”€â”€ phase8-advanced/
â”‚       â”œâ”€â”€ lab-21-ab-testing/
â”‚       â””â”€â”€ lab-22-technology-selection/
â”‚
â”œâ”€â”€ ğŸš€ scripts/                                # All executable scripts
â”‚   â”œâ”€â”€ elasticsearch/
â”‚   â”‚   â”œâ”€â”€ setup-es-ha.sh
â”‚   â”‚   â”œâ”€â”€ index-sample-data.sh
â”‚   â”‚   â”œâ”€â”€ query-examples.sh
â”‚   â”‚   â”œâ”€â”€ performance-tests.sh
â”‚   â”‚   â””â”€â”€ monitoring-es.sh
â”‚   â”œâ”€â”€ solr/
â”‚   â”‚   â”œâ”€â”€ setup-solr-ha.sh
â”‚   â”‚   â”œâ”€â”€ create-collections.sh
â”‚   â”‚   â”œâ”€â”€ index-sample-data.sh
â”‚   â”‚   â”œâ”€â”€ query-examples.sh
â”‚   â”‚   â””â”€â”€ monitoring-solr.sh
â”‚   â”œâ”€â”€ opensearch/
â”‚   â”‚   â”œâ”€â”€ setup-os-ha.sh
â”‚   â”‚   â”œâ”€â”€ index-sample-data.sh
â”‚   â”‚   â”œâ”€â”€ query-examples.sh
â”‚   â”‚   â””â”€â”€ monitoring-os.sh
â”‚   â””â”€â”€ common/
â”‚       â”œâ”€â”€ generate-test-data.sh
â”‚       â”œâ”€â”€ performance-comparison.sh
â”‚       â”œâ”€â”€ load-testing.sh
â”‚       â””â”€â”€ health-checks.sh
â”‚
â”œâ”€â”€ ğŸ“ˆ tools/                                  # Specialized tools and utilities
â”‚   â”œâ”€â”€ concurrent-load-tester/
â”‚   â”‚   â”œâ”€â”€ lab5-concurrent-load-tester.go
â”‚   â”‚   â”œâ”€â”€ build.sh
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ data-generators/
â”‚   â”‚   â”œâ”€â”€ blog-dataset-generator.py
â”‚   â”‚   â”œâ”€â”€ e-commerce-generator.py
â”‚   â”‚   â””â”€â”€ log-data-generator.py
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ prometheus-config.yml
â”‚       â”œâ”€â”€ grafana-dashboards.json
â”‚       â””â”€â”€ alerting-rules.yml
â”‚
â”œâ”€â”€ ğŸ“‹ data/                                   # All sample datasets
â”‚   â”œâ”€â”€ blog-posts/
â”‚   â”‚   â”œâ”€â”€ 20k-blog-dataset.json
â”‚   â”‚   â”œâ”€â”€ blog-mapping.json
â”‚   â”‚   â””â”€â”€ blog-schema.xml
â”‚   â”œâ”€â”€ e-commerce/
â”‚   â”‚   â”œâ”€â”€ products-dataset.json
â”‚   â”‚   â””â”€â”€ product-mapping.json
â”‚   â””â”€â”€ logs/
â”‚       â”œâ”€â”€ apache-access-logs.json
â”‚       â””â”€â”€ application-logs.json
â”‚
â”œâ”€â”€ ğŸ” configs/                                # All configuration files
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”‚   â””â”€â”€ upstream-config.conf
â”‚   â”œâ”€â”€ elasticsearch/
â”‚   â”‚   â”œâ”€â”€ jvm.options
â”‚   â”‚   â”œâ”€â”€ elasticsearch.yml
â”‚   â”‚   â””â”€â”€ index-templates/
â”‚   â”œâ”€â”€ solr/
â”‚   â”‚   â”œâ”€â”€ solr.xml
â”‚   â”‚   â”œâ”€â”€ solrconfig.xml
â”‚   â”‚   â””â”€â”€ collections/
â”‚   â””â”€â”€ opensearch/
â”‚       â”œâ”€â”€ opensearch.yml
â”‚       â”œâ”€â”€ jvm.options
â”‚       â””â”€â”€ index-templates/
â”‚
â””â”€â”€ ğŸ“ docs/                                   # Supporting documentation
    â”œâ”€â”€ troubleshooting.md
    â”œâ”€â”€ performance-tuning.md
    â”œâ”€â”€ production-deployment.md
    â””â”€â”€ api-reference.md
```

---

## ğŸ¯ **Unified HA Setup Strategy**

### **ğŸ—ï¸ Single Docker Compose Configuration**

```yaml
# docker-compose.yml - Master HA Configuration for All Learning Phases
version: '3.8'

services:
  # Elasticsearch HA Cluster (3 nodes)
  es-master-1:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-master-1
    environment:
      - node.name=es-master-1
      - cluster.name=lucene-learning-cluster
      - discovery.seed_hosts=es-master-2,es-master-3
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
      - node.roles=master,data,ingest
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - es-data-1:/usr/share/elasticsearch/data
      - ./configs/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9200:9200"
    networks:
      - lucene-network

  es-master-2:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-master-2
    environment:
      - node.name=es-master-2
      - cluster.name=lucene-learning-cluster
      - discovery.seed_hosts=es-master-1,es-master-3
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
      - node.roles=master,data,ingest
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - es-data-2:/usr/share/elasticsearch/data
    ports:
      - "9201:9200"
    networks:
      - lucene-network

  es-master-3:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es-master-3
    environment:
      - node.name=es-master-3
      - cluster.name=lucene-learning-cluster
      - discovery.seed_hosts=es-master-1,es-master-2
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
      - node.roles=master,data,ingest
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - es-data-3:/usr/share/elasticsearch/data
    ports:
      - "9202:9200"
    networks:
      - lucene-network

  # Solr HA Cluster (3 nodes)
  solr1:
    image: solr:9.4
    container_name: solr1
    hostname: solr1
    environment:
      - SOLR_HEAP=2g
      - ZK_HOST=zoo1:2181,zoo2:2181,zoo3:2181
      - SOLR_HOST=solr1
    volumes:
      - solr-data-1:/var/solr
      - ./configs/solr:/opt/solr/server/solr/configsets/custom
    ports:
      - "8983:8983"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    networks:
      - lucene-network

  solr2:
    image: solr:9.4
    container_name: solr2
    hostname: solr2
    environment:
      - SOLR_HEAP=2g
      - ZK_HOST=zoo1:2181,zoo2:2181,zoo3:2181
      - SOLR_HOST=solr2
    volumes:
      - solr-data-2:/var/solr
    ports:
      - "8984:8983"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    networks:
      - lucene-network

  solr3:
    image: solr:9.4
    container_name: solr3
    hostname: solr3
    environment:
      - SOLR_HEAP=2g
      - ZK_HOST=zoo1:2181,zoo2:2181,zoo3:2181
      - SOLR_HOST=solr3
    volumes:
      - solr-data-3:/var/solr
    ports:
      - "8985:8983"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    networks:
      - lucene-network

  # OpenSearch HA Cluster (3 nodes)
  opensearch-node1:
    image: opensearchproject/opensearch:2.11.0
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node1
      - discovery.seed_hosts=opensearch-node1,opensearch-node2,opensearch-node3
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2,opensearch-node3
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
      - plugins.security.disabled=true
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - opensearch-data1:/usr/share/opensearch/data
    ports:
      - "9300:9200"
    networks:
      - lucene-network

  opensearch-node2:
    image: opensearchproject/opensearch:2.11.0
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node2
      - discovery.seed_hosts=opensearch-node1,opensearch-node2,opensearch-node3
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2,opensearch-node3
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
      - plugins.security.disabled=true
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    ports:
      - "9301:9200"
    networks:
      - lucene-network

  opensearch-node3:
    image: opensearchproject/opensearch:2.11.0
    container_name: opensearch-node3
    environment:
      - cluster.name=opensearch-cluster  
      - node.name=opensearch-node3
      - discovery.seed_hosts=opensearch-node1,opensearch-node2,opensearch-node3
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2,opensearch-node3
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g"
      - plugins.security.disabled=true
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - opensearch-data3:/usr/share/opensearch/data
    ports:
      - "9302:9200"
    networks:
      - lucene-network

  # Zookeeper Ensemble for SolrCloud
  zoo1:
    image: zookeeper:3.9
    container_name: zoo1
    hostname: zoo1
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181
    volumes:
      - zoo1-data:/data
      - zoo1-datalog:/datalog
    networks:
      - lucene-network

  zoo2: 
    image: zookeeper:3.9
    container_name: zoo2
    hostname: zoo2
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181
    volumes:
      - zoo2-data:/data
      - zoo2-datalog:/datalog
    networks:
      - lucene-network

  zoo3:
    image: zookeeper:3.9
    container_name: zoo3
    hostname: zoo3  
    environment:
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181
    volumes:
      - zoo3-data:/data
      - zoo3-datalog:/datalog
    networks:
      - lucene-network

  # Nginx Load Balancer for HA Endpoints
  nginx:
    image: nginx:1.25
    container_name: nginx-lb
    volumes:
      - ./configs/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "9199:9199"  # Elasticsearch HA endpoint
      - "8999:8999"  # Solr HA endpoint  
      - "9399:9399"  # OpenSearch HA endpoint
    depends_on:
      - es-master-1
      - es-master-2
      - es-master-3
      - solr1
      - solr2
      - solr3
      - opensearch-node1
      - opensearch-node2
      - opensearch-node3
    networks:
      - lucene-network

  # Kibana for Elasticsearch
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=["http://nginx-lb:9199"]
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
    ports:
      - "5601:5601"
    depends_on:
      - nginx
    networks:
      - lucene-network

  # OpenSearch Dashboards
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.11.0
    container_name: opensearch-dashboards
    environment:
      - OPENSEARCH_HOSTS=["http://nginx-lb:9399"]
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true
    ports:
      - "5602:5601"
    depends_on:
      - nginx
    networks:
      - lucene-network

volumes:
  es-data-1: {}
  es-data-2: {}
  es-data-3: {}
  solr-data-1: {}
  solr-data-2: {}
  solr-data-3: {}
  opensearch-data1: {}
  opensearch-data2: {}
  opensearch-data3: {}
  zoo1-data: {}
  zoo1-datalog: {}
  zoo2-data: {}
  zoo2-datalog: {}
  zoo3-data: {}
  zoo3-datalog: {}

networks:
  lucene-network:
    driver: bridge
```

---

## ğŸ¯ **HA Endpoint Standardization**

### **ğŸ“Š Consistent Endpoint Usage Across All Materials**

```bash
# Standardized HA Endpoints - Use ONLY these URLs
ELASTICSEARCH_HA="http://localhost:9199"    # Nginx load-balanced Elasticsearch
SOLR_HA="http://localhost:8999"            # Nginx load-balanced Solr  
OPENSEARCH_HA="http://localhost:9399"      # Nginx load-balanced OpenSearch

# Administrative Interfaces
KIBANA="http://localhost:5601"             # Elasticsearch admin interface
SOLR_ADMIN="http://localhost:8983/solr"    # Solr admin interface (direct)
OPENSEARCH_DASHBOARDS="http://localhost:5602"  # OpenSearch admin interface

# Health Check Endpoints
ES_HEALTH="${ELASTICSEARCH_HA}/_cluster/health"
SOLR_HEALTH="${SOLR_HA}/admin/collections?action=CLUSTERSTATUS"
OS_HEALTH="${OPENSEARCH_HA}/_cluster/health"
```

---

## ğŸš€ **One-Time Setup Process**

### **âš¡ Master Setup Script**

```bash
#!/bin/bash
# setup/unified-setup.sh - One-time environment setup for all learning phases

echo "ğŸ¯ Lucene Ecosystem Learning Environment Setup"
echo "ğŸ“š Setting up Elasticsearch + Solr + OpenSearch HA clusters"
echo ""

# Step 1: Environment validation
echo "ğŸ” Step 1: Validating environment..."
./setup/verify-prerequisites.sh

# Step 2: Start all services
echo "ğŸš€ Step 2: Starting all services (this may take 5-10 minutes)..."
docker-compose up -d

# Step 3: Wait for cluster formation
echo "â³ Step 3: Waiting for cluster formation..."
./setup/wait-for-clusters.sh

# Step 4: Create initial configurations
echo "ğŸ”§ Step 4: Setting up initial configurations..."
./scripts/elasticsearch/setup-es-ha.sh
./scripts/solr/setup-solr-ha.sh  
./scripts/opensearch/setup-os-ha.sh

# Step 5: Load sample datasets
echo "ğŸ“Š Step 5: Loading sample datasets..."
./scripts/common/generate-test-data.sh
./scripts/elasticsearch/index-sample-data.sh
./scripts/solr/index-sample-data.sh
./scripts/opensearch/index-sample-data.sh

# Step 6: Verify everything is working
echo "âœ… Step 6: Final verification..."
./setup/verify-setup.sh

echo ""
echo "ğŸ‰ Setup Complete! All systems ready for learning journey."
echo ""
echo "ğŸ“‹ Access Points:"
echo "   Elasticsearch HA: http://localhost:9199"
echo "   Solr HA: http://localhost:8999"  
echo "   OpenSearch HA: http://localhost:9399"
echo "   Kibana: http://localhost:5601"
echo "   Solr Admin: http://localhost:8983/solr"
echo "   OpenSearch Dashboards: http://localhost:5602"
echo ""
echo "ğŸ“š Next Steps:"
echo "   1. Start with: learning-materials/00-LEARNING-PATH-README.md"
echo "   2. Follow sequential learning path: 01 â†’ 02 â†’ ... â†’ 22"
echo "   3. Execute labs independently from labs/ folders"
echo "   4. Use scripts/ for specific technology operations"
echo ""
echo "ğŸ¯ Happy Learning! Transform from novice to Senior Staff Engineer!"
```

---

## ğŸ“‹ **Lab Extraction Strategy**

### **ğŸ”„ From Markdown to Independent Labs**

```bash
# Example: Extracting Lab 14 (Progressive Performance Labs)
# FROM: 14-performance-progressive-labs.md (embedded content)
# TO: labs/phase6-performance/lab-14-progressive-performance/

labs/phase6-performance/lab-14-progressive-performance/
â”œâ”€â”€ README.md                          # Lab objectives and instructions
â”œâ”€â”€ lab1-baseline-establishment.sh     # Lab 1: Baseline Performance
â”œâ”€â”€ lab2-data-volume-scaling.sh        # Lab 2: Data Volume Impact
â”œâ”€â”€ lab3-concurrent-queries.sh         # Lab 3: Concurrent Analysis
â”œâ”€â”€ lab4-breaking-point.sh             # Lab 4: Breaking Point Discovery
â”œâ”€â”€ lab5-concurrent-readwrite.sh       # Lab 5: Concurrent Read/Write
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ lab1-config.json
â”‚   â”œâ”€â”€ lab2-config.json
â”‚   â”œâ”€â”€ lab3-config.json
â”‚   â”œâ”€â”€ lab4-config.json
â”‚   â””â”€â”€ lab5-config.json
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ baseline-dataset.json
â”‚   â”œâ”€â”€ scaling-dataset.json
â”‚   â””â”€â”€ stress-test-dataset.json
â””â”€â”€ results/
    â”œâ”€â”€ lab1-results.md
    â”œâ”€â”€ lab2-results.md
    â”œâ”€â”€ lab3-results.md
    â”œâ”€â”€ lab4-results.md
    â””â”€â”€ lab5-results.md
```

### **ğŸ“Š Script Standardization Example**

```bash
# labs/phase6-performance/lab-14-progressive-performance/lab1-baseline-establishment.sh

#!/bin/bash
# Lab 1: Baseline Performance Establishment
# Uses standardized HA endpoints throughout

# Configuration
ELASTICSEARCH_HA="http://localhost:9199"
SOLR_HA="http://localhost:8999"
OPENSEARCH_HA="http://localhost:9399"

echo "ğŸ” Lab 1: Baseline Performance Establishment"
echo "ğŸ“Š Testing all three platforms with standardized dataset"
echo ""

# Test Elasticsearch
echo "âš¡ Testing Elasticsearch via HA endpoint..."
curl -X POST "${ELASTICSEARCH_HA}/performance_baseline/_bulk" \
  -H "Content-Type: application/x-ndjson" \
  --data-binary @../../../data/blog-posts/20k-blog-dataset.json

# Measure indexing performance
time curl -X POST "${ELASTICSEARCH_HA}/performance_baseline/_doc" \
  -H "Content-Type: application/json" \
  -d '{"title":"Performance Test","content":"Baseline measurement","timestamp":"2024-01-01T00:00:00Z"}'

# Test query performance
time curl -X GET "${ELASTICSEARCH_HA}/performance_baseline/_search" \
  -H "Content-Type: application/json" \
  -d '{"query":{"match":{"content":"search"}},"size":10}'

# Test Solr
echo "âš¡ Testing Solr via HA endpoint..."
curl "${SOLR_HA}/admin/collections?action=CREATE&name=performance_baseline&numShards=3&replicationFactor=2&collection.configName=_default"

# Test OpenSearch  
echo "âš¡ Testing OpenSearch via HA endpoint..."
curl -X PUT "${OPENSEARCH_HA}/performance_baseline" \
  -H "Content-Type: application/json" \
  -d '{"settings":{"number_of_shards":3,"number_of_replicas":1}}'

echo "âœ… Lab 1 Complete - Baseline established for all platforms"
```

---

## ğŸ¯ **Benefits of This Reorganization**

### **âœ… Improved Organization**
- **Independent Execution**: Every lab can run standalone
- **Consistent HA Usage**: All scripts use load-balanced endpoints
- **Single Setup**: One-time environment creation for all learning phases
- **Technology Separation**: Clear organization by ES/Solr/OpenSearch
- **Phase-Based Structure**: Logical progression through learning journey

### **ğŸš€ Production Readiness**
- **HA Architecture**: Proper load balancing and clustering
- **Scalable Design**: Multi-node clusters for realistic performance testing
- **Monitoring Integration**: Built-in health checks and observability
- **Configuration Management**: Centralized configs for easy tuning

### **ğŸ“š Learning Efficiency**
- **Sequential Learning**: Clear progression path with prerequisites
- **Hands-On Practice**: Independent labs for each major concept
- **Real-World Scenarios**: Production-like environment setup
- **Expert Resources**: Curated materials from industry leaders

**This reorganization transforms your scattered learning materials into a professional, production-ready learning environment that scales from foundations to Senior Staff Engineer expertise!** ğŸ¯âœ¨
